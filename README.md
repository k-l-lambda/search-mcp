# Search MCP Server

A web search server based on Model Context Protocol (MCP) that supports multiple search engines with automatic fallback functionality.

## âœ¨ Features

- ğŸ” **Multiple Search Engine Support**
  - SerpAPI (recommended - requires API key)
  - Baidu
  - Google
  - DuckDuckGo
  - SearXNG
- ğŸ”„ Automatic fallback mechanism
- ğŸŒ Proxy support (automatically uses `http://localhost:1081`)
- ğŸ“¦ Fully compatible with MCP protocol
- ğŸ¯ Structured search results (title, link, snippet)

## ğŸ“¦ Installation

```bash
npm install
npm run build
```

## ğŸš€ Usage

### Option 1: Use SerpAPI (Recommended)

**Why SerpAPI?**
- âœ… Stable and reliable, no anti-scraping issues
- âœ… Free tier: 100 searches/month
- âœ… Supports multiple search engines (Google, Bing, Baidu, etc.)
- âœ… Official API, fast response

**Get API Key:**
1. Visit https://serpapi.com/
2. Register for a free account
3. Get your API Key

**Configuration:**
```bash
# Method 1: Use .env.local file (recommended)
cp .env.example .env.local
# Edit .env.local, add your API Key
# SERPAPI_KEY=your_api_key_here

# Method 2: Use environment variable
export SERPAPI_KEY="your_api_key_here"
```

**Test Search:**
```bash
# Build the project
npm run build

# Run test (automatically reads .env.local)
npm run dev
# or
npx tsx src/test.ts
```

### Option 2: Use Open Source Engines (May Encounter Anti-Scraping)

Directly use the scraper engines implemented in the code, but may encounter:
- 503 errors
- CAPTCHA blocking
- Timeout issues

## ğŸ”§ Claude Code Configuration

After configuring `.env.local`, add MCP server to Claude Code configuration:

**Recommended Configuration (using .env.local):**
```json
{
  "mcpServers": {
    "search": {
      "command": "node",
      "args": ["/home/ubuntu/work/search-mcp/dist/index.js"]
    }
  }
}
```

**Or specify environment variables in config:**
```json
{
  "mcpServers": {
    "search": {
      "command": "node",
      "args": ["/home/ubuntu/work/search-mcp/dist/index.js"],
      "env": {
        "SERPAPI_KEY": "your_serpapi_key_here"
      }
    }
  }
}
```

> **Tip:** Using `.env.local` file for key management is more secure and convenient.

## ğŸ› ï¸ Development

```bash
# Development mode
npm run dev

# Build
npm run build

# Run built version
npm start
```

## ğŸ“– Search Tool API

The MCP server provides a `web_search` tool with the following parameters:

- `query` (required): Search query string
- `engine` (optional): Search engine to use
  - `auto` (default): Automatically try all engines with fallback
  - `serpapi`: Use SerpAPI (requires SERPAPI_KEY)
  - `baidu`: Use Baidu only
  - `google`: Use Google only
  - `duckduckgo`: Use DuckDuckGo only
  - `searxng`: Use SearXNG only
- `max_results` (optional): Maximum number of results (1-50, default: 10)
- `language` (optional): Language preference (default: "en")

## ğŸ’¡ Usage Examples

Call in Claude Code:

```typescript
web_search({
  query: "gold price today",
  engine: "auto",
  max_results: 5
})
```

## ğŸŒ Environment Variables

- `https_proxy` / `HTTPS_PROXY`: Proxy server URL (default: http://localhost:1081)
- `SERPAPI_KEY`: SerpAPI key (optional but highly recommended)

## ğŸ“‚ Project Structure

```
search-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # MCP server entry point
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”œâ”€â”€ base.ts           # Search engine base class
â”‚   â”‚   â”œâ”€â”€ serpapi.ts        # SerpAPI implementation (recommended)
â”‚   â”‚   â”œâ”€â”€ baidu.ts          # Baidu search
â”‚   â”‚   â”œâ”€â”€ google.ts         # Google search
â”‚   â”‚   â”œâ”€â”€ duckduckgo.ts     # DuckDuckGo search
â”‚   â”‚   â”œâ”€â”€ searxng.ts        # SearXNG search
â”‚   â”‚   â””â”€â”€ manager.ts        # Search manager (fallback logic)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ http.ts           # HTTP client (proxy support)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ PLAN.md                    # Development plan
â”œâ”€â”€ SOLUTION.md                # Problem solutions
â””â”€â”€ README.md                  # This file
```

## âš ï¸ Anti-Scraping Issues

Due to strict anti-scraping measures by major search engines (Google, Baidu, DuckDuckGo), direct scraping may encounter:
- 503 Service Unavailable
- CAPTCHA blocking
- IP bans
- Request timeouts

**Strongly recommend using SerpAPI**, which provides official API access without anti-scraping concerns.

See `SOLUTION.md` for alternative solutions.

## ğŸ“ License

ISC
